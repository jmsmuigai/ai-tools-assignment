# -*- coding: utf-8 -*-
"""Amazon_NLP_spaCy

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A2mzBaFBe8-gK7ZgWMlj-zKQsbR_VtvO
"""

!pip install spacy
!python -m spacy download en_core_web_sm

import spacy
nlp = spacy.load("en_core_web_sm")

from google.colab import drive
import pandas as pd

# Mount Google Drive
drive.mount('/content/drive')

# Load your Amazon Reviews CSV or TXT file
file_path = '/content/drive/MyDrive/AI_Toolkit_Assignment/Amazon_Reviews/<your-file-name>.csv'
df = pd.read_csv(file_path)

# Show first few reviews
df.head()

import bz2

# Path to the compressed file in your Drive
file_path = '/content/drive/MyDrive/AI_Toolkit_Assignment/Amazon_Reviews/train.ft.txt.bz2'

# Open the compressed file
with bz2.open(file_path, 'rt') as f:
    lines = f.readlines()

# View a few sample reviews
for i in range(5):
    print(lines[i])

# Extract text only (removing labels)
reviews = [line.split(' ', 1)[1].strip() for line in lines if ' ' in line]

# Show first 5 cleaned reviews
for review in reviews[:5]:
    print(review)

import spacy
nlp = spacy.load("en_core_web_sm")

# Analyze first 5 reviews
for review in reviews[:5]:
    doc = nlp(review)
    print(f"Review: {review}")
    print("Entities found:")
    for ent in doc.ents:
        print(f" - {ent.text} ({ent.label_})")
    print("-" * 40)

positive_words = ['great', 'excellent', 'love', 'amazing', 'good', 'perfect']
negative_words = ['bad', 'terrible', 'poor', 'worst', 'hate', 'broken']

def analyze_sentiment(text):
    text = text.lower()
    if any(word in text for word in positive_words):
        return "Positive"
    elif any(word in text for word in negative_words):
        return "Negative"
    else:
        return "Neutral"

# Apply sentiment to first 10 reviews
for review in reviews[:10]:
    print(f"Review: {review}")
    print("Sentiment:", analyze_sentiment(review))
    print("-" * 30)

import bz2

file_path = '/content/drive/MyDrive/AI_Toolkit_Assignment/Amazon_Reviews/train.ft.txt.bz2'

# Load compressed file
with bz2.open(file_path, 'rt') as f:
    lines = f.readlines()

# Clean lines to extract review text (remove __label__ part)
reviews = [line.split(' ', 1)[1].strip() for line in lines if ' ' in line]

# Show first 5 review texts
for i in range(5):
    print(f"Review {i+1}: {reviews[i]}")

import spacy
nlp = spacy.load("en_core_web_sm")

# Apply NER to first 5 reviews
for i, review in enumerate(reviews[:5]):
    doc = nlp(review)
    print(f"\nReview {i+1}: {review}")
    print("Entities found:")
    for ent in doc.ents:
        print(f" - {ent.text} ({ent.label_})")

Ethical Reflection:
While building AI models for digit recognition and text sentiment, we identified potential biases in dataset composition and processing techniques. MNIST lacks handwriting diversity, and our sentiment rules may overlook context in user language. In future work, we'll explore fairness indicators and contextual NLP tools to improve ethical AI outcomes.

ethics_reflection = """
While building AI models for digit recognition and text sentiment,
we identified potential biases in dataset composition and processing techniques.
MNIST lacks handwriting diversity, and our sentiment rules may overlook context in user language.
In future work, we'll explore fairness indicators and contextual NLP tools to improve ethical AI outcomes.
"""

print(ethics_reflection)

